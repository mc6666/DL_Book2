{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失函數(Loss Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例1. 二分類交叉熵(BinaryCrossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81492424"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 兩筆資料實際及預測值\n",
    "y_true = [[0., 1.], [0., 0.]]     # 實際值\n",
    "y_pred = [[0.6, 0.4], [0.4, 0.6]] # 預測值\n",
    "\n",
    "# 二分類交叉熵(BinaryCrossentropy)\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "bce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.814924454847114"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 驗算\n",
    "import math\n",
    "\n",
    "((0-math.log(1-0.6) - math.log(0.4)) + (0-math.log(1-0.6) - math.log(0.6)) )/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2689414213699951, 0.11920292202211757, 0.04742587317756679, 0.7310585786300049, 0.8807970779778823, 0.9525741268224331]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9962590167116454"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 驗算\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** (-x))\n",
    "\n",
    "def BCE(output, target):\n",
    "    n = len(output)\n",
    "    total_value = 0\n",
    "    \n",
    "    output = list(map(sigmoid, output))\n",
    "    print(output)\n",
    "\n",
    "    for i in range(n):\n",
    "        total_value += (target[i]*math.log(output[i])+(1-target[i])*math.log(1-output[i]))\n",
    "   \n",
    "    total_value *= -1/n\n",
    "    return total_value\n",
    "\n",
    "y_pred = [-1, -2, -3, 1, 2, 3]\n",
    "y_true = [0, 1, 0, 0, 0, 1]\n",
    "BCE(y_pred, y_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例2. 多分類交叉熵(CategoricalCrossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1769392"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 兩筆資料實際及預測值\n",
    "y_true = [[0, 1, 0], [0, 0, 1]]     # 實際值\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]] # 預測值\n",
    "\n",
    "# 多分類交叉熵(CategoricalCrossentropy)\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "cce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例3. 稀疏矩陣的多分類交叉熵(SparseCategoricalCrossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1769392"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 兩筆資料實際及預測值\n",
    "y_true = [1, 2]     # 實際值\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]] # 預測值\n",
    "\n",
    "# 多分類交叉熵(CategoricalCrossentropy)\n",
    "cce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "cce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例4. MeanSquaredError：計算實際及預測值的均方誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 兩筆資料實際及預測值\n",
    "y_true = [[0., 1.], [0., 0.]]     # 實際值\n",
    "y_pred = [[1., 1.], [1., 0.]]     # 預測值\n",
    "\n",
    "# 多分類交叉熵(CategoricalCrossentropy)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "mse(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 樣本類別的權重比例\n",
    "mse(y_true, y_pred, sample_weight=[0.7, 0.3]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取總和，即 SSE，而非 MSE\n",
    "mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "mse(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例5. Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 兩筆資料實際及預測值\n",
    "y_true = [[0., 1.], [0., 0.]]     # 實際值\n",
    "y_pred = [[0.6, 0.4], [0.4, 0.6]] # 預測值\n",
    "\n",
    "# Hinge Loss\n",
    "loss_function = tf.keras.losses.Hinge()\n",
    "loss_function(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 驗算\n",
    "# loss = sum (maximum(1 - y_true * y_pred, 0))\n",
    "(max(1 - (-1) * 0.6, 0) + max(1 - 1 * 0.4, 0) + \n",
    "    max(1 - (-1) * 0.4, 0) + max(1 - (-1) * 0.6, 0)) / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例6. 自訂損失函數(Custom Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自訂損失函數(Custom Loss)\n",
    "def my_loss_fn(y_true, y_pred):\n",
    "    # MSE\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)  # axis=-1 須設為 -1\n",
    "\n",
    "model.compile(optimizer='adam', loss=my_loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
